{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T23:10:14.227138Z","iopub.status.busy":"2025-04-07T23:10:14.226837Z","iopub.status.idle":"2025-04-07T23:10:17.576638Z","shell.execute_reply":"2025-04-07T23:10:17.575736Z","shell.execute_reply.started":"2025-04-07T23:10:14.227115Z"},"trusted":true},"outputs":[],"source":["!pip install -q gitpython sentence-transformers faiss-cpu tqdm rank-bm25"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-04-07T23:10:17.578610Z","iopub.status.busy":"2025-04-07T23:10:17.578367Z","iopub.status.idle":"2025-04-07T23:11:34.063795Z","shell.execute_reply":"2025-04-07T23:11:34.062851Z","shell.execute_reply.started":"2025-04-07T23:10:17.578589Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Found 294 allowed files...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9c980c69bdb4532b6e9e7e4e53a8657","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/691 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02d132a0aeb04c0cbf745e9dd46012ec","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/504M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bfd3194c81e4e5bae778be8caf955a5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"024d8fc0404e43d9accb6e63d3542479","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/938k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"970b996dbece43f2bbbcd6d9f654bab2","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/444k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3e7f278b100474fb3dce0e77390acc7","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[INFO] Building file-level index for 294 files...\n","[INFO] Building BM25...\n","[INFO] Embedding entire files for Faiss with truncation...\n","[INFO] Done. 294 file-level embeddings created.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6f3b21afab5442f89e13f36c5ac5edb","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/791 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2731a24c4b44640a6f67c6a01baa7a7","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e02005d985e64aeaab3906764b3227ea","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbc62aba759b46379cc925f4744d3f15","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c252c05145b4059bbf9ac400835b078","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Recall@10: 0.68 ( 23 / 34 )\n","\n","Query: How does the application manage scrcpy for a device?\n","Top retrieved files:\n","   docs/en/reference/scrcpy/develop.md\n","   docs/en/reference/scrcpy/otg.md\n","   docs/en/reference/scrcpy/device.md\n","   docs/en/reference/scrcpy/audio.md\n","   develop.md\n","   docs/en/reference/scrcpy/control.md\n","   docs/en/reference/scrcpy/camera.md\n","   docs/en/reference/scrcpy/index.md\n","   docs/en/help/scrcpy.md\n","   docs/en/reference/scrcpy/tunnels.md\n"]}],"source":["import os\n","import json\n","from pathlib import Path\n","import git\n","import faiss\n","import numpy as np\n","\n","from tqdm import tqdm\n","from rank_bm25 import BM25Okapi\n","from sentence_transformers import SentenceTransformer, CrossEncoder\n","\n","import torch\n","\n","##############################################################################\n","# CONFIG\n","##############################################################################\n","GITHUB_REPO_URL = \"https://github.com/viarotel-org/escrcpy\"\n","REPO_LOCAL_PATH = Path(\"temp_escrcpy_repo\")\n","REFERENCE_JSON_PATH = Path(\"/kaggle/input/llm-listwise-reranker-for-coderag-jetbrains/escrcpy-commits-generated.json\")\n","\n","VECTOR_MODEL_NAME = \"microsoft/unixcoder-base\"\n","CROSS_ENCODER_MODEL_NAME = \"cross-encoder/ms-marco-MiniLM-L-12-v2\"\n","\n","ALLOWED_EXTENSIONS = [\".js\",\".ts\",\".vue\",\".md\",\".json\",\".py\",\".yml\",\".yaml\",\".html\",\".css\"]\n","\n","BM25_K = 200\n","EMB_K = 200\n","RERANK_CANDIDATES = 400\n","TOP_K = 10\n","\n","# Hard limit on file size in characters or lines, to skip insane files:\n","MAX_FILE_CHAR_LENGTH = 200_000\n","\n","##############################################################################\n","# 1) Clone or pull the repo\n","##############################################################################\n","def clone_repo_if_needed(repo_url, clone_path):\n","    if clone_path.exists():\n","        try:\n","            repo = git.Repo(str(clone_path))\n","            repo.remotes.origin.pull()\n","        except:\n","            pass\n","    else:\n","        git.Repo.clone_from(repo_url, clone_path)\n","\n","##############################################################################\n","# 2) List & read files\n","##############################################################################\n","def list_source_files(root_path, exts):\n","    files = []\n","    for p in root_path.rglob(\"*\"):\n","        if p.is_file() and p.suffix.lower() in exts:\n","            files.append(p)\n","    return files\n","\n","def read_file_text(fpath: Path):\n","    try:\n","        return fpath.read_text(encoding=\"utf-8\", errors=\"ignore\")\n","    except:\n","        return \"\"\n","\n","##############################################################################\n","# 3) Indexer: file-level indexing with truncation\n","##############################################################################\n","class FileLevelIndexer:\n","    def __init__(self, vector_model_name):\n","        # Turn on truncation to avoid the device-side asserts\n","        self.encoder = SentenceTransformer(vector_model_name)\n","        # Ensure max_seq_length is set to e.g. 512 or 1024\n","        self.encoder.max_seq_length = 512\n","\n","        # Another approach:\n","        # self.encoder.tokenizer.model_max_length = 512\n","        # self.encoder.tokenizer.truncation_side = 'right'\n","\n","        dim = self.encoder.get_sentence_embedding_dimension()\n","        self.faiss_index = faiss.IndexFlatIP(dim)\n","\n","        self.docstore = []  # each: {\"file_path\": str, \"content\": str}\n","        self.bm25_corpus = []\n","        self.bm25 = None\n","\n","    def build(self, file_list):\n","        print(f\"[INFO] Building file-level index for {len(file_list)} files...\")\n","\n","        for f in tqdm(file_list):\n","            rel_path = str(f.relative_to(REPO_LOCAL_PATH)).lower().lstrip(\"./\")\n","            content = read_file_text(f)\n","\n","            # Optional: skip extremely large files\n","            if len(content) > MAX_FILE_CHAR_LENGTH:\n","                continue\n","\n","            chunk_text = f\"FILEPATH: {rel_path}\\n\\n{content}\"\n","\n","            self.docstore.append({\n","                \"file_path\": rel_path,\n","                \"content\": chunk_text\n","            })\n","            self.bm25_corpus.append(chunk_text)\n","\n","        print(\"[INFO] Building BM25...\")\n","        tokenized = [doc.split() for doc in self.bm25_corpus]\n","        self.bm25 = BM25Okapi(tokenized)\n","\n","        print(\"[INFO] Embedding entire files for Faiss with truncation...\")\n","        embeddings = []\n","        for doc in tqdm(self.docstore, desc=\"Embedding for Faiss\"):\n","            emb = self.encoder.encode(doc[\"content\"], show_progress_bar=False)\n","            embeddings.append(emb)\n","        embeddings = np.array(embeddings, dtype=\"float32\")\n","        self.faiss_index.add(embeddings)\n","        print(f\"[INFO] Done. {len(self.docstore)} file-level embeddings created.\")\n","\n","    def bm25_search(self, query, top_k=50):\n","        tokens = query.split()\n","        scores = self.bm25.get_scores(tokens)\n","        sorted_idx = np.argsort(scores)[::-1]\n","        top_idx = sorted_idx[:top_k]\n","        results = []\n","        for i in top_idx:\n","            results.append({\"doc_id\": i, \"score\": float(scores[i])})\n","        return results\n","\n","    def faiss_search(self, query, top_k=50):\n","        q_emb = self.encoder.encode([query], show_progress_bar=False)\n","        D, I = self.faiss_index.search(q_emb.astype(\"float32\"), top_k)\n","        results = []\n","        for idx, score in zip(I[0], D[0]):\n","            results.append({\"doc_id\": idx, \"score\": float(score)})\n","        return results\n","\n","##############################################################################\n","# 4) Cross-Encoder re-ranker\n","##############################################################################\n","class CrossEncoderReranker:\n","    def __init__(self, model_name):\n","        self.ce = CrossEncoder(model_name)\n","\n","    def rerank(self, query, candidates, docstore, top_k=10):\n","        pairs = []\n","        for c in candidates:\n","            text = docstore[c[\"doc_id\"]][\"content\"]\n","            pairs.append((query, text))\n","        scores = self.ce.predict(pairs, show_progress_bar=False)\n","        for i, sc in enumerate(scores):\n","            candidates[i][\"rerank_score\"] = float(sc)\n","        # sort & slice\n","        candidates = sorted(candidates, key=lambda x: x[\"rerank_score\"], reverse=True)\n","        return candidates[:top_k]\n","\n","##############################################################################\n","# 5) Retrieval\n","##############################################################################\n","def retrieve_files(indexer, reranker, query,\n","                   bm25_k=200, emb_k=200, re_rank_candidates=400, top_k=10):\n","    # Merge BM25 + Faiss\n","    bm25_top = indexer.bm25_search(query, top_k=bm25_k)\n","    faiss_top = indexer.faiss_search(query, top_k=emb_k)\n","    combined_map = {}\n","    for r in bm25_top:\n","        combined_map[r[\"doc_id\"]] = r\n","    for r in faiss_top:\n","        if r[\"doc_id\"] in combined_map:\n","            combined_map[r[\"doc_id\"]][\"score\"] = max(combined_map[r[\"doc_id\"]][\"score\"], r[\"score\"])\n","        else:\n","            combined_map[r[\"doc_id\"]] = r\n","\n","    combined_list = list(combined_map.values())\n","    combined_list = sorted(combined_list, key=lambda x: x[\"score\"], reverse=True)\n","    combined_list = combined_list[:re_rank_candidates]\n","\n","    # Re-rank\n","    final_candidates = reranker.rerank(query, combined_list, indexer.docstore, top_k=re_rank_candidates)\n","\n","    # Return top_k unique files\n","    results = []\n","    seen = set()\n","    for c in final_candidates:\n","        file_path = indexer.docstore[c[\"doc_id\"]][\"file_path\"]\n","        if file_path not in seen:\n","            seen.add(file_path)\n","            results.append(file_path)\n","        if len(results) == top_k:\n","            break\n","    return results\n","\n","##############################################################################\n","# 6) Evaluation\n","##############################################################################\n","def evaluate_recall10(indexer, reranker, ref_path, top_k=10):\n","    with open(ref_path, \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    total = len(data)\n","    hits = 0\n","\n","    for item in data:\n","        query = item[\"question\"]\n","        # Normalize ground-truth paths\n","        gt = [fp.lower().lstrip(\"./\") for fp in item[\"files\"]]\n","        gt_set = set(gt)\n","\n","        retrieved = retrieve_files(indexer, reranker, query, top_k=top_k)\n","        overlap = gt_set & set(retrieved)\n","        if overlap:\n","            hits += 1\n","\n","    recall = hits / total if total else 0\n","    print(f\"Recall@{top_k}: {recall:.2f} ( {hits} / {total} )\")\n","\n","##############################################################################\n","# MAIN\n","##############################################################################\n","if __name__ == \"__main__\":\n","    clone_repo_if_needed(GITHUB_REPO_URL, REPO_LOCAL_PATH)\n","    files = list_source_files(REPO_LOCAL_PATH, ALLOWED_EXTENSIONS)\n","    print(f\"[INFO] Found {len(files)} allowed files...\")\n","\n","    # Build a file-level index\n","    indexer = FileLevelIndexer(VECTOR_MODEL_NAME)\n","    indexer.build(files)\n","\n","    # Cross-encoder\n","    reranker = CrossEncoderReranker(CROSS_ENCODER_MODEL_NAME)\n","\n","    # Evaluate\n","    if REFERENCE_JSON_PATH.exists():\n","        evaluate_recall10(indexer, reranker, REFERENCE_JSON_PATH, top_k=TOP_K)\n","    else:\n","        print(f\"[WARNING] No reference file at {REFERENCE_JSON_PATH}\")\n","\n","    # Demo\n","    q = \"How does the application manage scrcpy for a device?\"\n","    top_files = retrieve_files(indexer, reranker, q, top_k=10)\n","    print(\"\\nQuery:\", q)\n","    print(\"Top retrieved files:\")\n","    for x in top_files:\n","        print(\"  \", x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6959214,"sourceId":11154028,"sourceType":"datasetVersion"}],"dockerImageVersionId":30918,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
